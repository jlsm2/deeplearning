{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7Tlmfyx6v7I2KXCPM+yk0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlsm2/deeplearning/blob/main/cc_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento dos dados"
      ],
      "metadata": {
        "id": "5lxfzbmPvb13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download de bibliotecas"
      ],
      "metadata": {
        "id": "HtrxneW6vhj9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "5v6HprX1oC66"
      },
      "outputs": [],
      "source": [
        "!pip install d2l==1.0.3 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn seaborn matplotlib plotly -q"
      ],
      "metadata": {
        "id": "npppI-u4vm3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7f0aa2-38b1-492b-e5b8-1d52b59afb5e"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando bibliotecas"
      ],
      "metadata": {
        "id": "YkOEFIP_v3WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "waMtVh1Dv7BW"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o dataset"
      ],
      "metadata": {
        "id": "Fce9rVkP0iO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrain = pd.read_csv(\"fraudTrain.csv\")\n",
        "dfTest = pd.read_csv(\"fraudTest.csv\")\n",
        "\n",
        "dfTrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "jnL-lmF00lZ7",
        "outputId": "6dc82497-0cc7-4cb2-ae08-90a67281a94c"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-161-6799c55d1be8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fraudTrain.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdfTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fraudTest.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfTrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \"\"\"\n\u001b[1;32m   1337\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removendo colunas irrelevantes"
      ],
      "metadata": {
        "id": "uHBQe3wl3pRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrain.info()\n",
        "dfTest.info()"
      ],
      "metadata": {
        "id": "qO2I53N22KM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrain = dfTrain.drop(columns=[\"Unnamed: 0\", \"cc_num\", \"first\", \"last\", \"street\", \"city\", \"state\", \"zip\", \"dob\", \"trans_num\"])\n",
        "dfTest = dfTest.drop(columns=[\"Unnamed: 0\", \"cc_num\", \"first\", \"last\", \"street\", \"city\", \"state\", \"zip\", \"dob\", \"trans_num\"])"
      ],
      "metadata": {
        "id": "iHKuKXZRNDAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verificando se há valores nulos"
      ],
      "metadata": {
        "id": "4GP-SfE73bmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dfTrain.isnull().sum())\n",
        "print(dfTest.isnull().sum())"
      ],
      "metadata": {
        "id": "SeJTV5Kh3RQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convertendo colunas de data"
      ],
      "metadata": {
        "id": "HAwl3mXHPG7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataframe\n",
        "dfTrain[\"trans_date_trans_time\"] = pd.to_datetime(dfTrain[\"trans_date_trans_time\"])\n",
        "\n",
        "dfTrain[\"year\"] = dfTrain[\"trans_date_trans_time\"].dt.year\n",
        "dfTrain[\"month\"] = dfTrain[\"trans_date_trans_time\"].dt.month\n",
        "dfTrain[\"day\"] = dfTrain[\"trans_date_trans_time\"].dt.day\n",
        "dfTrain[\"day_of_week\"] = dfTrain[\"trans_date_trans_time\"].dt.dayofweek\n",
        "dfTrain[\"hour\"] = dfTrain[\"trans_date_trans_time\"].dt.hour\n",
        "\n",
        "dfTrain.drop(columns=[\"trans_date_trans_time\"], inplace=True)\n",
        "\n",
        "# test dataframe\n",
        "dfTest[\"trans_date_trans_time\"] = pd.to_datetime(dfTest[\"trans_date_trans_time\"])\n",
        "\n",
        "dfTest[\"year\"] = dfTest[\"trans_date_trans_time\"].dt.year\n",
        "dfTest[\"month\"] = dfTest[\"trans_date_trans_time\"].dt.month\n",
        "dfTest[\"day\"] = dfTest[\"trans_date_trans_time\"].dt.day\n",
        "dfTest[\"day_of_week\"] = dfTest[\"trans_date_trans_time\"].dt.dayofweek\n",
        "dfTest[\"hour\"] = dfTest[\"trans_date_trans_time\"].dt.hour\n",
        "\n",
        "dfTest.drop(columns=[\"trans_date_trans_time\"], inplace=True)\n",
        "\n",
        "\n",
        "dfTrain"
      ],
      "metadata": {
        "id": "pifTIfKUPJrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identificando e tratando variáveis categoricas"
      ],
      "metadata": {
        "id": "zYkvUcIJdPDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = dfTrain.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "print(categorical_cols)"
      ],
      "metadata": {
        "id": "_oT188EydSAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrain[\"merchant\"] = dfTrain[\"merchant\"].astype(\"category\")\n",
        "dfTrain[\"category\"] = dfTrain[\"category\"].astype(\"category\")\n",
        "dfTrain[\"gender\"] = dfTrain[\"gender\"].astype(\"category\")\n",
        "dfTrain[\"job\"] = dfTrain[\"job\"].astype(\"category\")\n",
        "\n",
        "dfTest[\"merchant\"] = dfTest[\"merchant\"].astype(\"category\")\n",
        "dfTest[\"category\"] = dfTest[\"category\"].astype(\"category\")\n",
        "dfTest[\"gender\"] = dfTest[\"gender\"].astype(\"category\")\n",
        "dfTest[\"job\"] = dfTest[\"job\"].astype(\"category\")"
      ],
      "metadata": {
        "id": "9cEcJDCDdscj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrain.info()\n",
        "dfTest.info()"
      ],
      "metadata": {
        "id": "4JdYDx64eLTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "dfTrain[\"merchant\"] = le.fit_transform(dfTrain[\"merchant\"])\n",
        "dfTrain[\"job\"] = le.fit_transform(dfTrain[\"job\"])\n",
        "\n",
        "dfTest[\"merchant\"] = le.fit_transform(dfTest[\"merchant\"])\n",
        "dfTest[\"job\"] = le.fit_transform(dfTest[\"job\"])\n",
        "\n",
        "# one-hot encoding\n",
        "dfTrain = pd.get_dummies(dfTrain, columns=[\"category\", \"gender\"], drop_first=True)\n",
        "\n",
        "dfTest = pd.get_dummies(dfTest, columns=[\"category\", \"gender\"], drop_first=True)"
      ],
      "metadata": {
        "id": "2lGQcPq1eoOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrain.info()"
      ],
      "metadata": {
        "id": "OILTZ-V4fAjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balanceando os casos de fraude"
      ],
      "metadata": {
        "id": "iIPLNppl-sYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = px.histogram(dfTrain, x=\"is_fraud\")\n",
        "\n",
        "graph.show()"
      ],
      "metadata": {
        "id": "wXW1bGBF8lwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dfTrain.drop(\"is_fraud\", axis=1)\n",
        "y = dfTrain[\"is_fraud\"]\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "XTrain_resampled, ytrain_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "X = dfTest.drop(\"is_fraud\", axis=1)\n",
        "y = dfTest[\"is_fraud\"]\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "XTest_resampled, ytest_resampled = smote.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "qEv5RCVJ-vuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = px.histogram(ytrain_resampled, x=\"is_fraud\")\n",
        "\n",
        "graph.show()"
      ],
      "metadata": {
        "id": "RDwQ-pru_xfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padronizando features numéricas"
      ],
      "metadata": {
        "id": "D-7aqS7-ffcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = [\"amt\", \"lat\", \"long\", \"city_pop\", \"unix_time\", \"year\", \"month\", \"day\", \"day_of_week\", \"hour\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "XTrain_resampled[numeric_features] = scaler.fit_transform(XTrain_resampled[numeric_features])\n",
        "XTest_resampled[numeric_features] = scaler.fit_transform(XTest_resampled[numeric_features])"
      ],
      "metadata": {
        "id": "A7wZ-esBfiiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XTrain_resampled"
      ],
      "metadata": {
        "id": "elc2vWNjf5yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XTest_resampled"
      ],
      "metadata": {
        "id": "JjlCBHhQkWsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identificando e tratando outliers\n"
      ],
      "metadata": {
        "id": "s5vrLY1v3jl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "# identificação dos outliers\n",
        "Q1 = XTrain_resampled[\"amt\"].quantile(0.25)\n",
        "Q3 = XTrain_resampled[\"amt\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = XTrain_resampled[(XTrain_resampled[\"amt\"] < lower_bound) | (XTrain_resampled[\"amt\"] > upper_bound)]\n",
        "\n",
        "# remoção\n",
        "XTrain_resampled_cleaned = XTrain_resampled[(XTrain_resampled[\"amt\"] >= lower_bound) & (XTrain_resampled[\"amt\"] <= upper_bound)]\n",
        "\n",
        "# substituicao de valores\n",
        "XTrain_resampled[\"amt\"] = np.where(XTrain_resampled[\"amt\"] < lower_bound, lower_bound, XTrain_resampled[\"amt\"])\n",
        "XTrain_resampled[\"amt\"] = np.where(XTrain_resampled[\"amt\"] > upper_bound, upper_bound, XTrain_resampled[\"amt\"])\n",
        "\n",
        "# transformação de dados\n",
        "XTrain_resampled[\"amt\"] = np.log(XTrain_resampled[\"amt\"] + 1)  # somar 1 para evitar log(0)"
      ],
      "metadata": {
        "id": "UbnBuv78j4Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=XTrain_resampled_cleaned[\"amt\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xgehrh2YnJPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "\n",
        "# identificação dos outliers\n",
        "Q1 = XTest_resampled[\"amt\"].quantile(0.25)\n",
        "Q3 = XTest_resampled[\"amt\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = XTest_resampled[(XTest_resampled[\"amt\"] < lower_bound) | (XTest_resampled[\"amt\"] > upper_bound)]\n",
        "\n",
        "# remoção\n",
        "XTest_resampled_cleaned = XTest_resampled[(XTest_resampled[\"amt\"] >= lower_bound) & (XTest_resampled[\"amt\"] <= upper_bound)]\n",
        "\n",
        "# substituicao de valores\n",
        "XTest_resampled[\"amt\"] = np.where(XTest_resampled[\"amt\"] < lower_bound, lower_bound, XTest_resampled[\"amt\"])\n",
        "XTest_resampled[\"amt\"] = np.where(XTest_resampled[\"amt\"] > upper_bound, upper_bound, XTest_resampled[\"amt\"])\n",
        "\n",
        "# transformação de dados\n",
        "XTest_resampled[\"amt\"] = np.log(XTest_resampled[\"amt\"] + 1)  # somar 1 para evitar log(0)"
      ],
      "metadata": {
        "id": "pqZpbmhokGS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=XTest_resampled_cleaned[\"amt\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pElwgX1aluw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisão dos dados"
      ],
      "metadata": {
        "id": "khk7Dx-Rm-nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = XTrain_resampled\n",
        "y_train = ytrain_resampled\n",
        "\n",
        "X_test = XTest_resampled\n",
        "y_test = ytest_resampled"
      ],
      "metadata": {
        "id": "RSBZJK5q7w1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criação e treinamento dos modelos"
      ],
      "metadata": {
        "id": "hz6_UWVL-N65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "f4uCKXMY-RxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [2, 5, 10, 20, 50]\n",
        "\n",
        "for n in estimators:\n",
        "  rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "  rf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = rf.predict(X_test)\n",
        "\n",
        "  print(f\"Acurácia[{n} estimators]: {accuracy_score(y_test, y_pred)}\")"
      ],
      "metadata": {
        "id": "85M4O-xk-Qmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "1jXSUyGXBB6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# redimensionando os dados\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "c-T4q6HnBEH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando o modelo\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, 64, batch_first=True, dropout=0.5)\n",
        "        self.fc = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "input_size = X_train.shape[2]\n",
        "model = LSTM(input_size)"
      ],
      "metadata": {
        "id": "qTCwGIxeGC2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# treinamento\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    predicted = (outputs > 0.5).float()\n",
        "    correct = (predicted == labels).float()\n",
        "    return correct.sum() / len(correct)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_accuracy += calculate_accuracy(outputs, labels).item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    avg_accuracy = running_accuracy / len(train_loader)\n",
        "    print(f'Época [{epoch + 1}/{num_epochs}], Perda: {avg_loss:.4f}, Acurácia: {avg_accuracy}')"
      ],
      "metadata": {
        "id": "2Gb8ole9GJwb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}